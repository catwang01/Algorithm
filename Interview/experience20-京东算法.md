
[toc]

[京东提前批-算法-一面_牛客博客](https://blog.nowcoder.net/n/125d060f9cab4ceb9e42bbf18e4ca9de)

1.自我介绍

2.问自动驾驶项目如何做的，输入输出是什么
参答：（1）双目摄像头：jpg图像 （2）激光雷达：pcd点云 （3）gnss： （4）惯导： （5）方向盘：CAN信息
比如通过摄像头采集到的前方路况图像，输入至YOLO算法里面，输出就是障碍物的类别、bounding box（w，h中，中心点，置信度）

3.过拟合、欠拟合是什么，有什么解决方案
欠拟合的原因：模型复杂度过低，不能很好的拟合所有的数据，训练误差大；
避免欠拟合：增加模型复杂度，如采用高阶模型（预测）或者引入更多特征（分类）等。
过拟合的原因：模型复杂度过高，训练数据过少，训练误差小，测试误差大；
避免过拟合：
• 降低模型复杂度
• 增加训练数据等。
• 正则化（L1、L2）：可以采用正则化对模型的复杂度进行约束
• 早停止（early stopping）：当验证集的泛化误差变大之后，停止训练。
• dropout（神经网络）
• 特征筛选
• 增大数据集
• 决策树剪枝
• SVM的松弛变量
• 集成学习
• batch normalization

4. 训练的时候批处理，mini-batch，随机梯度是什么
参答：

5.训练的时候遇到loss不变是什么原因，怎么处理
参答：
train loss 不断下降，test loss不断下降，说明网络仍在学习;
train loss 不断下降，test loss趋于不变，说明网络过拟合;
train loss 趋于不变，test loss不断下降，说明数据集100%有问题;
train loss 趋于不变，test loss趋于不变，说明学习遇到瓶颈，需要减小学习率或批量数目;
train loss 不断上升，test loss不断上升，说明网络结构设计不当，训练超参数设置不当，数据集经过清洗等问题。

6.bagging和boosting是什么，有什么区别，是怎么把弱模型变成强模型的
Bagging与Boosting的区别：
1）取样方式（样本权重）：Bagging是均匀选取，样本的权重相等，Boosting根据错误率取样，错误率越大则权重越大。2）训练集的选择：Bagging随机选择训练集，训练集之间相互独立，Boosting的各轮训练集的选择与前面各轮的学习结果有关。3）预测函数：Bagging各个预测函数没有权重，可以并行生成，Boosting有权重，顺序生成。4）Bagging是减少variance，Boosting是减少bias。
Bagging 是 Bootstrap Aggregating的简称，意思就是再取样 (Bootstrap) 然后在每个样本上训练出来的模型取平均，所以是降低模型的 variance. Bagging 比如 Random Forest 这种先天并行的算法都有这个效果。
Boosting 则是迭代算法，每一次迭代都根据上一次迭代的预测结果对样本进行加权，所以随着迭代不不断进行行，误差会越来越小，所以模型的 bias 会不不断降低。这种算法无法并行。

Bagging中的基模型为强模型(强模型拥有低偏差高方差)。
Boosting中的基模型为弱模型,若不是弱模型会导致整体模型的方差很大。

Bagging是从训练集中进行子抽样组成每个基模型所需要的子训练集,然后对所有基模型预测的结果进行综合操作产生最终的预测结果。
Boosting中基模型按次序进行训练,而基模型的训练集按照某种策略每次都进行一定的转化,最后以一定的方式将基分类器组合成一个强分类器