[toc] 


## 相关公司

1. [experience2-京东算法.md](experience2-京东算法.md)
2. [experience5-360 商业化ML 面经.md](experience5-360%20商业化ML%20面经.md)
3. [experience19-头条推荐.md](experience19-头条推荐.md)

## ML相关

### 其它

#### aux 的具体含义

京东 算法：GBDT的原理、LR的原理、对数据倾斜处理的方法
样本不平衡的处理方法（涉及到业务知识）

## 特征工程相关

7. 在做特征工程时采用了哪些方法呢？ 常见的筛选特征的方法有哪些？ ( 飞书算法 )
 
### svm

### XGBoost

XGboost、lightgbm、Catboost三者介绍
XGboost的原理及改进，
one-hot、 label-encoder对于category类型变量的处理方式，

3. 聚类算法了解程度、kmeans介绍、K值选择、kmeans++算法

1. 对xgboost的了解 ( 京东算法 )

#### 2. xgboost和lightgbm的区别 ( 京东算法x2 )

### LR相关

1. LR的随机梯度实现
3. 口述逻辑回归，写下其损失函数
2. 什么是线性模型？LR为什么是线性模型？ （飞书算法）
4. 如何提升LR的模型性能？ （飞书算法）

### 正则相关

2. 正则化手段 (京东算法)
4、口述l1和l2正则化
3. 从原理上解释L1, L2正则（如L1正则为什么能够起到特征选择的作用）
4. L1和L2的区别？L1有什么缺点？L2呢？平时用L1多还是用L2多？为什么正则化选L2呢？为什么不选L1？L1为什么产生稀疏解？ （飞书算法）

## DL相关

### 优化器相关

1. 几种梯度下降的方法和优缺点？ (飞书算法)
2. (todo) 平时怎么选择优化器？讲一下adam的优点 [experience2-京东算法.md](experience2-京东算法.md)
3. Adam的原理、公式 (没答上来) [experience19-头条推荐.md](experience19-头条推荐.md)

### 激活函数相关

1. sigmoid和relu的区别？平时用什么用的多？为什么用relu多呢？ （飞书算法）

2. 口述了解的激活函数，为什么要激活函数 (京东算法)
Sigmoid，Tanh，Relu等激活函数的优缺点（这里之前没有复习到，后面想了想应该从梯度消失，数据压缩，0均值方面来解释；当然，说的越多越好，比如Relu的神经元dead啥的，越能体现你的知识广度）

3. 为什么要用ReLU替代tanh/sigmoid/softmax
答：ReLU求导的值要么是0要么是1，不会引起梯度消失或梯度爆炸 [experience19-头条推荐.md](experience19-头条推荐.md)

#### 5. dnn中如果把中间层的激活函数去掉会怎样？去掉激活函数的dnn与逻辑回归有什么区别？


### CNN 相关

1. (todo) resnet结构 [experience2-京东算法.md](experience2-京东算法.md)
2. ResNet (todo) [experience19-头条推荐.md](experience19-头条推荐.md)
答：通过x + f(x)的结果，让深层网络获得不差于浅层网络的学习能力，从而允许网络变得更深


### 1. Pooling种类，区别以及适用场景
### 4. 谈谈1*1卷积

### RNN 相关

#### LSTM 和 GRU

1. lstm结构 [experience2-京东算法.md](experience2-京东算法.md)

2. (todo) gru跟lstm有什么区别？ [experience2-京东算法.md](experience2-京东算法.md)


### BN

1. bn怎么实现的？inference时候具体怎么做的？ [experience2-京东算法.md](experience2-京东算法.md)

2. 然后又讲到神经网络，BN层的作用？每个Batch_size的样本的均值的问题？ （这个不太理解是什么问题了，我答的是根据大数定律batch均值期望跟所有样本均值相接近，答完就觉得很扯。。。面试官说其实是动量，计算时会用到之前的batch_size的均值）
[experience5-360 商业化ML 面经.md](experience5-360%20商业化ML%20面经.md)

3. Batch Normalization的原理
答：在mini_batch上进行而不是在整个数据集上进行。在训练集上有BN测试集上没有BN，这样不会发生数值上的偏移，道理类似dropout，即记录下训练集上的BN参数（均值、标准差、\beta、\gamma）作为网络参数的一部分。
[experience19-头条推荐.md](experience19-头条推荐.md)


### Dropout

1. (todo) Dropout的原理 (为什么训练时有dropout测试时没有dropout，这样会发生scale的偏移吗) [experience19-头条推荐.md](experience19-头条推荐.md)

### 7. Attention机制

## 推荐系统相关

### 百度 系统设计：推荐系统有A信息如下，类似于user_id、ad_id、ad信息，B信息如下，包括图像信息、ad_id(即ad与原生图像之间的信息)，对于出现的广告，如何对该广告进行合理配图

### 百度 推荐系统的框架了解（召回和ranking）

### 百度 系统设计：推荐系统还有融合框架，假如通过两种不同的召回和ranking系统得到结果，如何在两种备选结果中最终给用户推荐出最适合的十个广告

1. DIN 和 DIEN 网络结构介绍

### 3. 谈谈Youtube的那篇《Deep Neural Networks for YouTube Recommendations》
### 4. DIN结构，DIN提出动机以及与之前模型的区别
### 6. DIN中Attention机制实现
### 4、deepwalk优缺点 (京东算法)
### 5、对推荐算法有什么了解 (京东算法)

### CTR相关

#### 6、ctr中会遇到什么问题，怎么解决 (京东算法)
#### 5. CTR预估模型的演化过程中的着手点

### FM模型

#### 1. 谈谈FM与DeepFM
#### 2. 谈谈FM的泛化能力
#### 5、FM模型与LR区别 (京东算法)
#### 3、口述deepfm (京东算法)

## NLP相关

讲一下文本分类模型。
给一个新的文本分类任务，会怎么选模型？
6、word2vec和bert区别 (京东算法)
w2v的原理，

## 开放题

1. 开放题：如果让你去解决一个陌生领域的问题，从分析问题到设计模型以及评价指标，你会怎么做？

2. 矩阵求逆是如何操作的？【答：高斯消元】描述过程？【答：左边一个A，右边一个I，消消消，消到左边的A变成I，右边的I就变成了A的逆矩阵】为什么可以这样算？如何证明？ [experience19-头条推荐.md](experience19-头条推荐.md)
答：高斯消元由矩阵行变换组成，矩阵行变换等价于左乘另外一个系数矩阵，所以当左边的A变到I，A就左乘了A的逆矩阵，同时右边的I也左乘了A的逆矩阵得到A的逆矩阵。这就是高斯消元法的原理。（马后炮分析，面试的时候没答上来，是面试官提示的）

3. 一个负载均衡里面产生的数学问题：现在有两台服务器A和B，后台算法是A和B都有1/2的概率被访问，如果访问的服务器宕机，则会以1/2的概率继续请求两个服务器。现在服务器B宕机了，求平均访问的次数？ [experience19-头条推荐.md](experience19-头条推荐.md)
答：这是一个随机变量求期望的问题。记平均访问的次数为p，

​ p = 1/2 * 1 + (1/2)^2 * 2 + (1/2)^3 * 3 + … + (1/2)^n * n + …

令q = 1/2 * p = (1/2)^2 * 1 + (1/2)^3 * 2 + … + (1/2)^n * (n-1) + …

故p = 2 (p - q) = 2 * [1/2 + (1/2)^2 + (1/2)^3 + …] = 2 * (1/2)/[1 - (1/2)] = 2

## HR

1. 说一下自己的优缺点
2. 内推你的人是谁？从他那了解了哪些信息？
3. 谈谈对部门业务的了解
4. 你觉得如果你来实习的话，你最想提升自己的哪些方面？或者说相比其他人，你的优势和劣势在哪里？
5. 目前还有公司在面试吗？进展如何？



