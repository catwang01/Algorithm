[toc]

[5月新浪微博算法实习面经_panda_zjd的博客-CSDN博客_新浪算法实习面经](https://blog.csdn.net/panda_zjd/article/details/71747127?locationNum=5&fps=1)

面试分了两轮，时间长达2个多小时。

一面：面试官看过我的简历后，告知我简历内容偏少，我所做项目没有能和他们部门匹配，希望我能够尽可能的描述自己的能力，看能不能匹配上部门（微博搜索部）的工作….尴尬…..一面主要还是问项目，让我描述简历中提到的两个机器学习项目，并详细讨论了项目中所用的模型和方法（RF，GBDT，时间序列的处理方法），随后讨论了一些特征工程的问题（属性的选择，降维方法，异常值处理方法）。聊完项目后，面试官考察我的编码能力，出了一道python的文本处理题（很难），我大概写了30多分钟，2页白纸，很多语法都忘记了，用汉语代替…..囧，一面到此结束（题目在最后描述）。
二面: 面试官出了三道题，其中2道数组的题，一道情景题，面试时间较短，大概40分钟，做题过程中面试官比较冰冷，不提示任何消息，每当我给出一道题的解法，如果正确但有更好的解法时，面试官会希望你能给出更优的解题思路，如果错误，面试官仅仅会举出反例….情景题比较简单，具体问题我在最后描述，面试到此结束，此时已经到了5点多，于是匆匆忙忙的走了。

具体讨论的问题：

1. GBDT，Xgboost，RF模型在实际应用中的参数，以及如何调参，Bagging和Boosting采样的区别，以及进行bagging和Boosting的数学意义是什么。
2. 如果模型发生过拟合，应该怎么样处理，如果调参后（已无法通过调参解决问题）还是过拟合，又该怎么办？
属性选择的方法有哪些，具体说明。
3. GBDT+LR模型融合的方法，以及对比只用GBDT和用GBDT+LR有什么区别？哪种方法更加有效？
4. GBDT和Xgboost的区别，哪些是解决过拟合问题的。
5. 用Python处理文本，文本内容是100棵GBDT树的逻辑，要求读取txt文本的内容对某个样本做训练，输出该样本进过100棵树学习后的结果….（对于我而言简直地狱难度….很多正则的语法都忘记了，强行硬着头皮写了40分钟，需要考虑的点非常多，比如TXT读出的数据都是string类型，每行的结尾都有换行符要处理等，小细节很多，很难受，整个过程就像不使用任何工具库，去写爬虫爬页面上的数据，并对这些数据进行分析得出最后的结果。这个面试官一点都不按套路出牌…..）

6. 数组题，寻找一个数组内所有符合如下规则的值：
    1.某个值左侧的点都比这个值小
    2某个值右侧的点都比这个值大
    3.要求只遍历数组一遍，找出所有符合要求的值。

7. 数组题，一个正整数数组如[23,456,789,457,453]，找出最小的两个数的拼接结果，如本题为 23和453 的拼接23453。例子只是用来说明，目标是求这样拼接的算法策略。

8. 如何得到一段时间（如一个月内）新浪微博所有用户发出的微博的总数量。要求不能访问新浪微博数据库。

答案以后陆续更新，有关GBDT的问题的答案，请访问http://blog.csdn.net/panda_zjd/article/details/71577463
本次面试除了一面的最后一道题比较难之外，其他还好，由于被一面那题折磨的太惨，二面答题的时候已经懵逼了，发挥的不是很好，很多该第一时间想到的答案没能想到，之前面百度和新浪以前也面过很多小公司，感觉大公司的面试更加细致，会抓很细节的东西去问，而小公司很宏观，小公司招人的唯一标准就是你能不能来了就能干活……

写在最后，感慨一下，找实习，找工作还是要拼人品，拼运气的….本次微博的面试，我和我的舍友面同一个部门（部门挑选的简历，很巧是不是），他是做自然语言处理和QA方向的，他研究的方向和部门的产品和技术十分吻合，于是欢快愉悦的聊了一个小时，就通知下周来HR面了…..很气，然而并没有什么用，谁让我只是一个渣渣的搞特征工程和数据预处理的咸鱼….加油啊，咸鱼也要有梦想的，不是么？

后记：收到新浪微博搜索部实习offer。面试官难为你，也许只是为了测试你有多大潜力….